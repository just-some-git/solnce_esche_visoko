Backend - часть проекта

Установка в терминале для Windows

1. Клонируйте репозиторий
```commandline
git clone https://github.com/just-some-git/solnce_esche_visoko.git
```
2. Установите требуемую версию **python** из файла *pythonversion.txt*
3. Перейдите в каталог *back*, создайте и активируйте виртуальную среду
```sh
cd passes_base
python -m venv venv
venv\scripts\activate
```
4. Установите необходимые модули
```sh
pip install -r requirements.txt
cd back
```

Запуск

Запустите сервер при помощи команды ```python manage.py runserver```

Тестирование front

Для тестирования соединения используем get-запрос
  ```http://127.0.0.1:8000/question/```

Возможные ответы в формате json:
Примеры:
```json
{"status": 200, "message": "Hello!"}
```

Для отравки аудио файла используем post-запрос
  ```http://127.0.0.1:8000/question/```

Файл прикрепляется в поле form-data: key - <file>, value - <сам файл>

Возможные ответы:
```json
{"status": 200} - отправляется аудиофайл
{"status": 500} - ServerError
```

Для получения текта, соответствующего аудио файлу используем get-запрос
  ```http://127.0.0.1:8000/answer/<название файла с расширением>```
Возможные ответы:
```json
{"status": 200, "filename":  <название файла>, "text":  <текст>}
{"status": 400} - BadRequest
{"status": 500} - ServerError
```

Тестирование DS

Для тестирования необходимо заменить строку в файле views.py с вызовом метода
входной аргумент метода input_file - текстовая строка с путем до файла
выходные параметры метода output_json в формате {'path': <путь до файла>, 'audio': <имя файла>, 'text': <разбивка по времени>}
___

Класс Voice Generator содержит в себе три модели машинного обучения на вход принимает путь к аудиофайлу-запросу, сохраняет аудиофайл-ответ и передает словарь с двумя ключами "path" где хранится путь к файлу-ответу и "text" где хранится сгенерированный транскрипт.
Используемые библиотеки: whisper,elevenlabs, g4f, os, datetime, загружаются при обращении к питон-файлу
__init__ загружает модели машинного обучения чтения голоса и голос диктора для последующей генерации при инициализации объекта класса
_get_unique_filename приватный метод класса генерации уникального имени файла и пути к файлу
load_path публичный метод класса принимает на вход путь к аудиофайлу-запросу в строковом варианте и возвращает словарь с указанием пути к файлу-ответу и текстом запроса. модель whisper считывает аудиофайл-запрос и переводит его в текст, полученный запрос в текстовом варианте передается в модель g4f где при помощи генеративного предобученного трансформера подготавливается ответ в текстовом варианте. далее текстовый вариант ответа переводится в аудиофайл и сохраняется под уникальным названием в локальной папке answer 

пример использования
# Создание экземпляра класса VoiceGenerator
generator = VoiceGenerator()

# Вызов метода load_path, передавая путь к аудиофайлу
result = generator.load_path("путь_к_вашему_аудиофайлу.wav")

# Визуализация результата
print("Путь к аудиофайлу:", result["path"])
print("Сгенерированный текст:", result["answer"])
